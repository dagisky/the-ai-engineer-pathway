{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5376b330-4b3e-4288-adec-62bde4d49ab7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "When working with Large Language Models (LLMs) through the OpenAI API or Langchain, there are two main ways to interact with them:\n",
    "* Instruct/Completion Models\n",
    "* Chat Models\n",
    "\n",
    "## Instruct/Completion Models\n",
    "* Fine-tuned with supervised learning + reinforcement learning from human feedback (RLHF) to follow instructions in plain prompts.\n",
    "* E.g., \"Translate this sentence into French: Hello, how are you?\"\n",
    "* Used in Legacy models that take a single prompt string and generate a continuation.\n",
    "  \n",
    "**Example**: `gpt-3.5-turbo-instruct` \n",
    "\n",
    "Good for one-shot tasks like “summarize this paragraph” or “translate this text.”\n",
    "\n",
    "Input: prompt=\"...\"\n",
    "Output: plain text in response.choices[0].text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29fda835-bf25-481c-92ab-f1b25b552b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635c2991-7b57-4f47-8586-51b861b52080",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "open_api_key = os.getenv(\"OPEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1357fc4a-bca7-4447-b0a1-a7e8f701b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter notebooks, a digital canvas\n",
      "Where ideas and data intertwine\n",
      "With each line of code, a new path unravels\n",
      "Reproducible research, a brilliant design\n",
      "\n",
      "With cells and kernels, the story unfolds\n",
      "A journey of analysis and insight\n",
      "From data to findings, the tale is told\n",
      "In a notebook, reproducible and right\n",
      "\n",
      "No more lost scripts or tangled code\n",
      "Jupyter notebooks, a researcher's delight\n",
      "Reproducible research, a smoother road\n",
      "To share knowledge and make science ignite\n",
      "\n",
      "So let us embrace this powerful tool\n",
      "And strive for research that's truly sound\n",
      "For with Jupyter notebooks, we can rule\n",
      "And make reproducibility abound.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = OpenAI(api_key=open_api_key)\n",
    "\n",
    "resp = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Write a short poem about Jupyter notebooks and reproducible research.\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=200\n",
    ")\n",
    "print(resp.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94cc03c-0460-46ab-863e-07ab2158f666",
   "metadata": {},
   "source": [
    "#### Langchain Example instruct/completion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a65f40-f89a-4531-b66b-30ddc0361083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa66e60c-42a4-438e-a65f-6d70917724b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In the world of coding and data,\n",
      "LangChain and Jupyter notebooks lead the way,\n",
      "With their power and flexibility,\n",
      "They make tasks seem like child's play.\n",
      "\n",
      "With LangChain's language agnostic style,\n",
      "And Jupyter's interactive interface,\n",
      "Coding and analyzing become a breeze,\n",
      "Making programmers' lives a paradise.\n",
      "\n",
      "Together they create a dynamic duo,\n",
      "Efficiently handling data flow,\n",
      "With each line of code and cell of text,\n",
      "They make complex tasks seem effortless.\n",
      "\n",
      "So here's to LangChain and Jupyter,\n",
      "The perfect pair for coding and data,\n",
      "Their seamless integration and endless possibilities,\n",
      "Make them the tech world's beloved enigma.\n"
     ]
    }
   ],
   "source": [
    "# Initialize completion model\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.7, api_key=open_api_key)\n",
    "\n",
    "# Run a simple prompt\n",
    "response = llm.invoke(\"Write a short poem about LangChain and Jupyter notebooks.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063e866-1592-418b-bea7-41dd4ef62c6e",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "Modern default for most OpenAI models (e.g., gpt-3.5-turbo, gpt-4, gpt-4o).\n",
    "Designed for conversational use. They accept a list of messages with roles:\n",
    "\n",
    "* Fine-tuned with dialogue datasets containing roles (system, user, assistant).\n",
    "* They learn to handle multi-turn interactions naturally.\n",
    "* RLHF is applied in a chat setting, where human trainers rate multi-turn conversations.\n",
    "\n",
    "**Example**\n",
    "```\n",
    "Input: messages=[\n",
    "system/SystemMessage → defines assistant’s behavior/personality\n",
    "user/HumanMessage → what the human asks\n",
    "assistant/AIMessage → model replies\n",
    "]\n",
    "```\n",
    "`Output: text in response.choices[0].message.content`\n",
    "\n",
    "Supports multi-turn context, tool/function calling, and multimodal inputs (like images for GPT-4o)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e154c4f4-e4c8-4fdb-88d2-ae141698a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da15d69-0d32-4ea5-aa83-9a8933f95939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "514efde3-a21e-475e-aeb6-2960889e4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client\n",
    "client = OpenAI(api_key=open_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aa113d5-c1d6-4670-ac7e-7cf56459d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a completion\n",
    "# Chat completion with GPT-4o\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI tutor.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a short poem about LangChain and Jupyter notebooks.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sure! (previous answer) LangChain links thoughts,\\nNotebooks hum with tidy code—\\nIdeas flow in cells.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Great—now make it funnier and 2 lines only.\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4da63b06-1bf6-4310-857e-0e9989ffcf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain whispers, \"AI's the boss,\"  \n",
      "Jupyter's like, \"Hold my loss!\"\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fedb40-085e-450d-b253-6e45e516f4a1",
   "metadata": {},
   "source": [
    "#### Langchain Chat Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9b1e22-fc70-4d51-a5ec-e01214aead65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9026fa1b-9e83-4c0c-8b05-b57cdb4aa4ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework designed to streamline the development of applications using large language models (LLMs). It offers tools for building complex chains of prompts and managing interactions with LLMs, enabling developers to integrate these models into their software more effectively.\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    api_key=open_api_key,  # <-- explicit key\n",
    ")\n",
    "\n",
    "msgs = [\n",
    "    SystemMessage(content=\"You are a concise AI tutor.\"),\n",
    "    HumanMessage(content=\"Explain LangChain in one paragraph.\"),\n",
    "    AIMessage(content=\"LangChain is a framework that helps you build LLM apps\"),   # ← prior assistant message\n",
    "    HumanMessage(content=\"Great—now refine that into 2 crisp sentences.\")\n",
    "]\n",
    "resp = chat.invoke(msgs)\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae60a73-6b57-4cf5-b2b9-bacfa7c39114",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c726b-2e95-4b5e-9ebe-9748f5217c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
