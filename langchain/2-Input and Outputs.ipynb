{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ab2326-d77e-417c-a960-793c69e2af82",
   "metadata": {},
   "source": [
    "# üì•üì§Inputs and Outputs (Model I/O)\n",
    "\n",
    "In LangChain, Model I/O (Input/Output) is the layer that defines how you interact with models. It provides standardized abstractions for sending prompts into models and parsing their responses.\n",
    "\n",
    "## üîë Why do we need Model I/O\n",
    "* **Consistency across models**: You can swap between OpenAI, Anthropic, Llama, etc. without changing your business logic, since LangChain standardizes the I/O.\n",
    "* **Structured outputs**: Instead of working with free-form text, you can parse model responses into JSON, Pydantic objects, or enums. This reduces errors and hallucinations.\n",
    "* **Composable pipelines**: Model I/O integrates with other LangChain pieces (retrievers, memory, tools) so you can **chain models and functions easily**.\n",
    "* **Flexibility**:\n",
    "    * Fine control over prompts (system + human messages, variable substitution).\n",
    "    * Choice of parsers (regex, structured, function-calling).\n",
    "    * Input/output transformations before/after the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220f6ef-9d3e-40d3-8bd4-cc212370a1e4",
   "metadata": {},
   "source": [
    "# üì•Inputs\n",
    "Inputs are the starting point of any interaction with an LLM-powered workflow. They represent the information you feed into your chain, agent, or model so it can generate a useful output.\n",
    "\n",
    "**Types of Inputs**\n",
    "\n",
    "* Raw Strings\n",
    "  > The simplest input is just plain text (e.g., \"What‚Äôs the capital of France?\").\n",
    "* Structured Inputs (Dictionaries)\n",
    "  > Many LangChain components expect a dictionary with key‚Äìvalue pairs.\n",
    "  \n",
    "Inputs are usually combined with **PromptTemplates and variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301c92d-aef7-46ba-ba2d-3b432d621b97",
   "metadata": {},
   "source": [
    "# üìù Prompt Templates and Input Variables\n",
    "A Prompt template in LangChain is a reusable way to create dynamic prompts for LLMs.\n",
    "Instead of hardcoding the full prompt string, you define a template with placeholders, and later fill those placeholders with variables at runtime.\n",
    "This ensures:\n",
    "\n",
    "* Consistency ‚Äì Reuse the same structure for different inputs.\n",
    "* Flexibility ‚Äì Easily swap variables without rewriting prompts.\n",
    "* Maintainability ‚Äì Keeps your LLM app organized as prompts grow.\n",
    "\n",
    "LangChain Uses two types of prompt templates\n",
    "1. **PromptTemplate** (for completion models)\n",
    "2. **ChatPromptTemplate** (for chat models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1660b1bc-0695-43e9-ac19-d171e5ab8479",
   "metadata": {},
   "source": [
    "## ‚ú®PromptTemplate\n",
    "* **Purpose**: Used for text-based LLMs (completion models).\n",
    "* **Output**: A single string prompt.\n",
    "* **Use case**: When you want to generate a plain text prompt (no roles like ‚Äúsystem‚Äù or ‚Äúuser‚Äù)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01c8ce-55fa-431e-8376-f15a45223d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## google colab\n",
    "# %pip install langchain openai\n",
    "# %pip install langchain langchain-community openai\n",
    "# %pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50f5cf9c-b51b-4e1d-9c1e-328d902c603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9eb6a16-7c73-418c-8cb6-77207b956217",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<Your API KEY>\" # Google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16a13b3-9f45-463c-9cef-c9773df60c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0, api_key=os.getenv(\"OPEN_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88d639d6-c51e-4d9a-8bb5-689eba782cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are three benefits of using LangChain?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Single input variable: \"product\"\n",
    "single_input_template = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What are three benefits of using {product}?\"\n",
    ")\n",
    "\n",
    "# template = \"What are three benefits of using {product}?\"\n",
    "# prompt = PromptTemplate.from_template(template)\n",
    "# print(prompt.format(product=\"LangChain\"))\n",
    "\n",
    "# Format with input\n",
    "formatted_prompt = single_input_template.format(product=\"LangChain\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1a5b3cd-a0fc-4447-8ecc-27654677444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response: \n",
      "\n",
      "1. Increased Efficiency: LangChain utilizes blockchain technology to automate and streamline language translation processes, resulting in increased efficiency and reduced turnaround times. This can save businesses time and resources, allowing them to focus on other important tasks.\n",
      "\n",
      "2. Enhanced Security: With its decentralized and immutable nature, LangChain offers enhanced security for language translation services. This means that translations are less susceptible to tampering or manipulation, ensuring the accuracy and integrity of the translated content.\n",
      "\n",
      "3. Cost Savings: By eliminating intermediaries and automating processes, LangChain can significantly reduce the costs associated with language translation services. This makes it a more affordable option for businesses and individuals looking to translate content into multiple languages.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(formatted_prompt)\n",
    "print(\"LLM response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9aee05-abc1-404b-af60-f3f1fb56b1f8",
   "metadata": {},
   "source": [
    "## üí¨ChatPromptTemplate\n",
    "* **Purpose**: Used for chat-based LLMs (like OpenAI‚Äôs GPT-4, GPT-4o, GPT-3.5).\n",
    "* **Output**: A list of message objects (with roles: system, human, ai, etc.).\n",
    "* **Use case**: When you need structured multi-role prompts (system instructions + user queries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56099d17-7e85-4eab-a272-0acbcff33e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document as a string\n",
    "document_text = \"\"\"\n",
    "LangChain is a framework for developing applications powered by language models.\n",
    "It provides abstractions for prompts, chains, agents, memory, and integrates with many external tools.\n",
    "\"\"\"\n",
    "\n",
    "# Define the chat prompt template with system + human messages\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use the provided document to answer questions.\"),\n",
    "    (\"human\", \"Here is the document:\\n{document}\\n\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "# Format the prompt with input variables\n",
    "messages = chat_prompt.format_messages(\n",
    "    document=document_text,\n",
    "    question=\"What does LangChain provide?\"\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=os.getenv(\"OPEN_API_KEY\"))\n",
    "\n",
    "# Get the response\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07692f6a-09af-4d94-a332-6cd383b7b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc07fe6-7e32-4ef7-a156-561f03db7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document string\n",
    "document_text = \"\"\"\n",
    "LangChain is a framework for developing applications powered by language models.\n",
    "It provides abstractions for prompts, chains, agents, memory, and integrates with many external tools.\n",
    "\"\"\"\n",
    "\n",
    "# Create system and human message prompt templates\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Use the provided document to answer questions.\"\n",
    ")\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"Here is the document:\\n{document}\\n\\nQuestion: {question}\"\n",
    ")\n",
    "\n",
    "# Build the chat prompt template\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "# Format with inputs\n",
    "messages = chat_prompt.format_messages(\n",
    "    document=document_text,\n",
    "    question=\"What does LangChain provide?\"\n",
    ")\n",
    "\n",
    "# Initialize LLM\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0,  api_key=os.getenv(\"OPEN_API_KEY\"))\n",
    "\n",
    "# Invoke the model\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bcd791-de57-41a7-ab4c-30e69821fc1a",
   "metadata": {},
   "source": [
    "# Few Shots Prompt-Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf3a7cf-de6a-48c4-b460-67de731c492a",
   "metadata": {},
   "source": [
    "In LangChain, a few-shot template is a way to guide a language model by giving it examples of how it should respond before asking the real question. The idea comes from few-shot learning, where instead of training the model with lots of data, you show it just a handful of demonstrations right inside the prompt.\n",
    "\n",
    "LangChain makes this easier with **FewShotPromptTemplate**. Instead of manually writing out all examples in one long string, you define a template for the examples and then let LangChain format them dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "301409a5-d0bd-45ad-90e4-24077536f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    FewShotPromptTemplate, \n",
    "    FewShotChatMessagePromptTemplate, \n",
    "    PromptTemplate, \n",
    "    ChatPromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31653847-9597-458e-89f4-eaf36e21d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=os.getenv(\"OPEN_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8510b8ff-b28e-4fa7-b163-06b12a6f9bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I loved the storyline and the acting was brilliant!\n",
      "Sentiment: Positive\n",
      "\n",
      "\n",
      "Review: The movie was too long and really boring.\n",
      "Sentiment: Negative\n",
      "\n",
      "\n",
      "Review: Amazing visuals and great soundtrack.\n",
      "Sentiment: Positive\n",
      "\n",
      "\n",
      "Review: The plot was confusing and poorly executed.\n",
      "Sentiment:\n",
      "=== Final Prompt Sent to LLM ===\n",
      "Review: I loved the storyline and the acting was brilliant!\n",
      "Sentiment: Positive\n",
      "\n",
      "\n",
      "Review: The movie was too long and really boring.\n",
      "Sentiment: Negative\n",
      "\n",
      "\n",
      "Review: Amazing visuals and great soundtrack.\n",
      "Sentiment: Positive\n",
      "\n",
      "\n",
      "Review: The plot was confusing and poorly executed.\n",
      "Sentiment:\n",
      "\n",
      "=== Model Output ===\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "# Template for each example\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"review\", \"sentiment\"],\n",
    "    template=\"Review: {review}\\nSentiment: {sentiment}\\n\"\n",
    ")\n",
    "\n",
    "# Few-shot examples\n",
    "examples = [\n",
    "    {\"review\": \"I loved the storyline and the acting was brilliant!\", \"sentiment\": \"Positive\"},\n",
    "    {\"review\": \"The movie was too long and really boring.\", \"sentiment\": \"Negative\"},\n",
    "    {\"review\": \"Amazing visuals and great soundtrack.\", \"sentiment\": \"Positive\"},\n",
    "]\n",
    "\n",
    "# FewShotPromptTemplate with suffix for new input\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Review: {input}\\nSentiment:\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "# Format with a new review\n",
    "print(few_shot_prompt.format(input=\"The plot was confusing and poorly executed.\"))\n",
    "# 4. Instantiate an LLM\n",
    "\n",
    "\n",
    "# 5. Format the prompt with a new review\n",
    "formatted_prompt = few_shot_prompt.format(input=\"The plot was confusing and poorly executed.\")\n",
    "print(\"=== Final Prompt Sent to LLM ===\")\n",
    "print(formatted_prompt)\n",
    "\n",
    "# 6. Call the LLM\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(\"\\n=== Model Output ===\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd4fcce9-2e4a-4e83-bc84-d3dd092a7958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Prompt Messages ===\n",
      "SYSTEM: You are a helpful assistant that classifies movie reviews as Positive or Negative.\n",
      "HUMAN: Review: I loved the storyline and the acting was brilliant!\n",
      "AI: Positive\n",
      "HUMAN: Review: The movie was too long and really boring.\n",
      "AI: Negative\n",
      "HUMAN: Review: Amazing visuals and great soundtrack.\n",
      "AI: Positive\n",
      "HUMAN: Review: The plot was confusing and poorly executed.\n",
      "\n",
      "=== Model Output ===\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "# 1) Build a chat prompt for each example (human ‚Üí ai)\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Review: {review}\"),\n",
    "    (\"ai\", \"{sentiment}\"),\n",
    "])\n",
    "\n",
    "# 2) Few-shot examples\n",
    "chat_examples = [\n",
    "    {\"review\": \"I loved the storyline and the acting was brilliant!\", \"sentiment\": \"Positive\"},\n",
    "    {\"review\": \"The movie was too long and really boring.\", \"sentiment\": \"Negative\"},\n",
    "    {\"review\": \"Amazing visuals and great soundtrack.\", \"sentiment\": \"Positive\"},\n",
    "]\n",
    "\n",
    "# 3) Few-shot block (no input_variables here)\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=chat_examples,\n",
    "    example_prompt=example_prompt,\n",
    ")\n",
    "\n",
    "# 4) Full chat prompt (system + few-shot + new human input)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that classifies movie reviews as Positive or Negative.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"Review: {input}\"),\n",
    "])\n",
    "\n",
    "# 6) Format and invoke\n",
    "messages = chat_prompt.format_messages(input=\"The plot was confusing and poorly executed.\")\n",
    "print(\"=== Final Prompt Messages ===\")\n",
    "for m in messages:\n",
    "    print(m.type.upper() + \":\", m.content)\n",
    "\n",
    "resp = llm.invoke(messages)\n",
    "print(\"\\n=== Model Output ===\")\n",
    "print(resp.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c9bcf-c307-4081-bf62-32c935c153dd",
   "metadata": {},
   "source": [
    "## Prompt Serialization\n",
    "In LangChain, prompt serialization means saving your PromptTemplate (or ChatPromptTemplate) into a file (JSON/YAML) and later loading it back.\n",
    "This makes your prompts:\n",
    "* Reusable ‚Üí Share prompts between projects or teams.\n",
    "* Maintainable ‚Üí Keep prompt logic outside your Python code.\n",
    "* Configurable ‚Üí Update prompts without touching source code.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf99a085-f09c-46c6-a5d4-edd170e2a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Prompt: What are three benefits of using LangChain?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, load_prompt\n",
    "\n",
    "# Define a prompt\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What are three benefits of using {product}?\"\n",
    ")\n",
    "\n",
    "# Save to JSON file\n",
    "prompt.save(\"prompt.json\")\n",
    "\n",
    "# Load it back\n",
    "loaded_prompt = load_prompt(\"prompt.json\")\n",
    "\n",
    "print(\"Loaded Prompt:\", loaded_prompt.format(product=\"LangChain\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a949f13-f448-41ae-9e04-6002da6bb9f3",
   "metadata": {},
   "source": [
    "# üì§ Outputs\n",
    "Just like Inputs are how you feed data into LangChain, Outputs are what you get back from a model, chain, or agent after processing.\n",
    "\n",
    "### **Types of Outputs**\n",
    "* **Raw Strings**\n",
    "> The simplest form: just text from the LLM.\n",
    "> Example: \"The capital of France is Paris.\"\n",
    "\n",
    "* **Message Objects**\n",
    "\n",
    "> For chat models, outputs can be structured as AIMessage.\n",
    "\n",
    "* **Structured Objects**\n",
    "> Sometimes you want structured data, not free text.\n",
    "> LangChain supports Output Parsers that turn text into:\n",
    "\n",
    "    > 1. JSON / Python dicts\n",
    "    > 2. Lists\n",
    "    > 3. Numbers\n",
    "    > 4. Pydantic models (typed objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43d055-5692-44fa-8224-c410a91ce3cd",
   "metadata": {},
   "source": [
    "#### 1Ô∏è‚É£ JSON / Python dicts\n",
    "\n",
    "Use StructuredOutputParser or JsonOutputParser to enforce JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a631979-84ce-4c61-840f-807648e211ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'genre': 'Science Fiction', 'recommendations': [{'title': 'Arrival', 'year': 2016, 'reason': 'A thought-provoking exploration of language and time.', 'director': 'Denis Villeneuve'}, {'title': 'Ex Machina', 'year': 2014, 'reason': 'A tense examination of artificial intelligence and ethics.', 'director': 'Alex Garland'}, {'title': 'Blade Runner 2049', 'year': 2017, 'reason': \"A visually stunning sequel that expands on the original's themes.\", 'director': 'Denis Villeneuve'}, {'title': 'Annihilation', 'year': 2018, 'reason': 'A surreal journey into an alien environment with deep psychological themes.', 'director': 'Alex Garland'}, {'title': 'The Platform', 'year': 2019, 'reason': 'A Spanish film that offers a unique take on class and survival.', 'director': 'Galder Gaztelu-Urrutia'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ---- JSON shape hint (plain text, no Pydantic) ----\n",
    "schema_hint = \"\"\"\n",
    "Return ONLY one JSON object with this shape:\n",
    "{\n",
    "  \"genre\": string,\n",
    "  \"recommendations\": [\n",
    "    {\n",
    "      \"title\": string,\n",
    "      \"year\": integer,\n",
    "      \"reason\": string,\n",
    "      \"director\": string|null\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You recommend movies strictly for the requested genre. \"\n",
    "     \"Do not include explanations, code fences, or extra text. \"\n",
    "     \"Output must be a single valid JSON object.\"),\n",
    "    (\"human\",\n",
    "     \"Genre: {genre}\\n\"\n",
    "     \"How many: {k}\\n\"\n",
    "     \"Constraints: {constraints}\\n\"\n",
    "     \"Return exactly {k} items in 'recommendations'.\\n\\n\"\n",
    "     \"{schema_hint}\\n\"\n",
    "     \"{format_instructions}\")\n",
    "]).partial(\n",
    "    schema_hint=schema_hint,\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "out = chain.invoke({\n",
    "    \"genre\": \"Science Fiction\",\n",
    "    \"k\": 5,\n",
    "    \"constraints\": \"Prefer post-2010; include at least one non-English film.\"\n",
    "})\n",
    "\n",
    "print(out)  # -> plain dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04bf9d2-9633-4af8-a73f-65ac6803aff0",
   "metadata": {},
   "source": [
    "#### 2Ô∏è‚É£ Lists\n",
    "Use `CommaSeparatedListOutputParser` for comma-separated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7a4a5a3-14a0-4b14-a1cb-656feee3cebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'cherry']\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "print(parser.parse(\"apple, banana, cherry\"))\n",
    "# ‚Üí [\"apple\", \"banana\", \"cherry\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f978412-b0fc-423d-86ff-8ab25690deae",
   "metadata": {},
   "source": [
    "#### 3Ô∏è‚É£ Numbers\n",
    "Use a simple OutputParser that ensures numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "459e6d87-2f19-4067-9ee9-0750fa59108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class IntOutputParser(BaseOutputParser[int]):\n",
    "    def parse(self, text: str) -> int:\n",
    "        return int(text.strip())\n",
    "\n",
    "parser = IntOutputParser()\n",
    "print(parser.parse(\" 42 \"))\n",
    "# ‚Üí 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf84456-b859-4bb9-9249-e13461960f10",
   "metadata": {},
   "source": [
    "#### 4Ô∏è‚É£ Pydantic Models (typed objects)\n",
    "\n",
    "With PydanticOutputParser, you define a schema ‚Üí enforce typed outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5018147b-20bc-48f4-b811-5d37ed0ca23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre='Science Fiction' recommendations=[Recommendation(title='Arrival', year=2016, reason='A thought-provoking exploration of language and time through the arrival of extraterrestrial beings.', director='Denis Villeneuve'), Recommendation(title='Ex Machina', year=2014, reason='A gripping tale of artificial intelligence and the ethical dilemmas surrounding it.', director='Alex Garland'), Recommendation(title='Blade Runner 2049', year=2017, reason='A visually stunning sequel that expands on the themes of identity and humanity.', director='Denis Villeneuve'), Recommendation(title='Annihilation', year=2018, reason='A mind-bending journey into a mysterious zone that alters everything it touches.', director='Alex Garland'), Recommendation(title='The Platform', year=2019, reason='A Spanish film that uses a unique setting to explore themes of class and survival.', director='Galder Gaztelu-Urrutia')]\n",
      "{'genre': 'Science Fiction', 'recommendations': [{'title': 'Arrival', 'year': 2016, 'reason': 'A thought-provoking exploration of language and time through the arrival of extraterrestrial beings.', 'director': 'Denis Villeneuve'}, {'title': 'Ex Machina', 'year': 2014, 'reason': 'A gripping tale of artificial intelligence and the ethical dilemmas surrounding it.', 'director': 'Alex Garland'}, {'title': 'Blade Runner 2049', 'year': 2017, 'reason': 'A visually stunning sequel that expands on the themes of identity and humanity.', 'director': 'Denis Villeneuve'}, {'title': 'Annihilation', 'year': 2018, 'reason': 'A mind-bending journey into a mysterious zone that alters everything it touches.', 'director': 'Alex Garland'}, {'title': 'The Platform', 'year': 2019, 'reason': 'A Spanish film that uses a unique setting to explore themes of class and survival.', 'director': 'Galder Gaztelu-Urrutia'}]}\n",
      "[Recommendation(title='Arrival', year=2016, reason='A thought-provoking exploration of language and time through the arrival of extraterrestrial beings.', director='Denis Villeneuve'), Recommendation(title='Ex Machina', year=2014, reason='A gripping tale of artificial intelligence and the ethical dilemmas surrounding it.', director='Alex Garland'), Recommendation(title='Blade Runner 2049', year=2017, reason='A visually stunning sequel that expands on the themes of identity and humanity.', director='Denis Villeneuve'), Recommendation(title='Annihilation', year=2018, reason='A mind-bending journey into a mysterious zone that alters everything it touches.', director='Alex Garland'), Recommendation(title='The Platform', year=2019, reason='A Spanish film that uses a unique setting to explore themes of class and survival.', director='Galder Gaztelu-Urrutia')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dagi\\AppData\\Local\\Temp\\ipykernel_49416\\2829697271.py:48: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(out.dict())          # -> plain dict\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1) Define your typed schema\n",
    "class Recommendation(BaseModel):\n",
    "    title: str = Field(..., description=\"Movie title\")\n",
    "    year: int = Field(..., description=\"Release year\")\n",
    "    reason: str = Field(..., description=\"Why this matches the request\")\n",
    "    director: Optional[str] = Field(None, description=\"Director if known\")\n",
    "\n",
    "class MovieRecs(BaseModel):\n",
    "    genre: str\n",
    "    recommendations: List[Recommendation]\n",
    "\n",
    "# 2) Make a Pydantic parser for that schema\n",
    "parser = PydanticOutputParser(pydantic_object=MovieRecs)\n",
    "\n",
    "# 3) Build the prompt, using the parser‚Äôs format instructions\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You recommend movies strictly for the requested genre. \"\n",
    "     \"Do not include explanations, code fences, or extra text. \"\n",
    "     \"Output must be a single valid JSON object that matches the schema.\"),\n",
    "    (\"human\",\n",
    "     \"Genre: {genre}\\n\"\n",
    "     \"How many: {k}\\n\"\n",
    "     \"Constraints: {constraints}\\n\"\n",
    "     \"Return exactly {k} items in 'recommendations'.\\n\\n\"\n",
    "     \"{format_instructions}\")\n",
    "]).partial(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 5) Invoke ‚Üí returns a MovieRecs Pydantic object\n",
    "out: MovieRecs = chain.invoke({\n",
    "    \"genre\": \"Science Fiction\",\n",
    "    \"k\": 5,\n",
    "    \"constraints\": \"Prefer post-2010; include at least one non-English film.\"\n",
    "})\n",
    "\n",
    "# Pydantic object usage\n",
    "print(out)                 # -> MovieRecs(...)\n",
    "print(out.dict())          # -> plain dict\n",
    "print(out.recommendations) # -> List[Recommendation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200daedb-f65c-4066-97a5-27d758f928ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
