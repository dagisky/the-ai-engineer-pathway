{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63a8e1a-fcba-4c59-8c48-0cdef3b4147a",
   "metadata": {},
   "source": [
    "# 🛠️ Tools\n",
    "In LangChain, Tools are essentially functions or APIs that the language model can call whenever it needs to go beyond plain text generation. You can think of them as the “hands” of the LLM. The model is very good at reasoning and language, but it can’t do things like query a database, run code, or fetch live data on its own. Tools bridge that gap by letting the model interact with the outside world.\n",
    "\n",
    "Each tool has a name, a short description, and a function behind it. The description is important because it guides the model on when to use the tool.\n",
    "\n",
    "**For Example**\n",
    "\n",
    "You might have a tool called “calculator” with the description “use this for arithmetic operations.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99246957-c16d-4a08-b0a4-07412c76b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## google colab\n",
    "# %pip install langchain openai\n",
    "# %pip install langchain langchain-community openai\n",
    "# %pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121d1219-3c9d-4825-beec-99a8d3d3e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(\"calculator\", description=\"Use this tool to do arithmetic calculations and evalute math expressions.\")\n",
    "def calculator(query: str) -> str:\n",
    "    try:\n",
    "        return str(eval(query))\n",
    "    except Exception:\n",
    "        return \"Error in calculation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2755fb-fabd-4d53-a719-e0ed478112c0",
   "metadata": {},
   "source": [
    "### Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "054bec54-98f1-4cfd-894b-824f918d91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "053ea69c-dcb3-41aa-aa81-ffe573797f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=os.getenv(\"OPEN_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4325c2c6-947b-4772-80f0-097c10bb3c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of \\(24 \\times 19\\) is 456. As for the (fake) weather in Dallas, it's 95°F and sunny.\n"
     ]
    }
   ],
   "source": [
    "# --- Define tools (structured I/O strongly recommended) ---\n",
    "class CalcInput(BaseModel):\n",
    "    expression: str = Field(..., description=\"A valid Python arithmetic expression, e.g. '2 + 2*10'\")\n",
    "\n",
    "@tool(\"calculator\", args_schema=CalcInput)\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Use this tool to do arithmetic calculations and evalute math expressions.\"\"\"\n",
    "    # Do not use eval in real apps; use a proper parser. This is a demo.\n",
    "    try:\n",
    "        return str(eval(query))\n",
    "    except Exception:\n",
    "        return \"Error in calculation\"\n",
    "\n",
    "class WeatherIn(BaseModel):\n",
    "    city: str = Field(..., description=\"City name, e.g. 'Dallas'\")\n",
    "\n",
    "@tool(\"fake_weather\", args_schema=WeatherIn)\n",
    "def fake_weather(city: str) -> str:\n",
    "    \"\"\"Return a mock weather string (demo).\"\"\"\n",
    "    return f\"Weather in {city}: 95°F, sunny.\"\n",
    "\n",
    "tools = [calculator, fake_weather]\n",
    "\n",
    "# --- Bind tools to the model ---\n",
    "router = llm.bind_tools(tools)\n",
    "\n",
    "# --- Simple tool loop: model decides -> we execute -> feed result back ---\n",
    "def ask(prompt: str):\n",
    "    # 1) Ask the model\n",
    "    res = router.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    # 2) If it requested tool(s), run them and return final answer\n",
    "    msgs = [HumanMessage(content=prompt), res]\n",
    "    if hasattr(res, \"tool_calls\") and res.tool_calls:\n",
    "        for tc in res.tool_calls:\n",
    "            name = tc[\"name\"]\n",
    "            args = tc[\"args\"] or {}\n",
    "            fn = next(t for t in tools if t.name == name)\n",
    "            output = fn.invoke(args)  # run the tool\n",
    "            msgs.append(ToolMessage(tool_call_id=tc[\"id\"], content=str(output)))\n",
    "\n",
    "        # 3) Give tool outputs back to the model for the final answer\n",
    "        final = llm.invoke(msgs)\n",
    "        return final.content\n",
    "\n",
    "    # No tool call—model answered directly\n",
    "    return res.content\n",
    "\n",
    "print(ask(\"What's 24*19? Then tell me the (fake) weather in Dallas.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1ead3-8566-4279-96bf-fe82c1d8aec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
