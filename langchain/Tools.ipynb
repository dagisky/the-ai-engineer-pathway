{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63a8e1a-fcba-4c59-8c48-0cdef3b4147a",
   "metadata": {},
   "source": [
    "# ðŸ› ï¸ Tools\n",
    "In LangChain, Tools are essentially functions or APIs that the language model can call whenever it needs to go beyond plain text generation. You can think of them as the â€œhandsâ€ of the LLM. The model is very good at reasoning and language, but it canâ€™t do things like query a database, run code, or fetch live data on its own. Tools bridge that gap by letting the model interact with the outside world.\n",
    "\n",
    "Each tool has a name, a short description, and a function behind it. The description is important because it guides the model on when to use the tool.\n",
    "\n",
    "**For Example**\n",
    "\n",
    "You might have a tool called â€œcalculatorâ€ with the description â€œuse this for arithmetic operations.â€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99246957-c16d-4a08-b0a4-07412c76b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## google colab\n",
    "# %pip install langchain openai\n",
    "# %pip install langchain langchain-community openai\n",
    "# %pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121d1219-3c9d-4825-beec-99a8d3d3e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(\"calculator\", description=\"Use this tool to do arithmetic calculations and evalute math expressions.\")\n",
    "def calculator(query: str) -> str:\n",
    "    try:\n",
    "        return str(eval(query))\n",
    "    except Exception:\n",
    "        return \"Error in calculation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2755fb-fabd-4d53-a719-e0ed478112c0",
   "metadata": {},
   "source": [
    "### Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "054bec54-98f1-4cfd-894b-824f918d91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "053ea69c-dcb3-41aa-aa81-ffe573797f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=os.getenv(\"OPEN_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4325c2c6-947b-4772-80f0-097c10bb3c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of \\(24 \\times 19\\) is 456. As for the (fake) weather in Dallas, it's 95Â°F and sunny.\n"
     ]
    }
   ],
   "source": [
    "# --- Define tools (structured I/O strongly recommended) ---\n",
    "class CalcInput(BaseModel):\n",
    "    expression: str = Field(..., description=\"A valid Python arithmetic expression, e.g. '2 + 2*10'\")\n",
    "\n",
    "@tool(\"calculator\", args_schema=CalcInput)\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Use this tool to do arithmetic calculations and evalute math expressions.\"\"\"\n",
    "    # Do not use eval in real apps; use a proper parser. This is a demo.\n",
    "    try:\n",
    "        return str(eval(query))\n",
    "    except Exception:\n",
    "        return \"Error in calculation\"\n",
    "\n",
    "class WeatherIn(BaseModel):\n",
    "    city: str = Field(..., description=\"City name, e.g. 'Dallas'\")\n",
    "\n",
    "@tool(\"fake_weather\", args_schema=WeatherIn)\n",
    "def fake_weather(city: str) -> str:\n",
    "    \"\"\"Return a mock weather string (demo).\"\"\"\n",
    "    return f\"Weather in {city}: 95Â°F, sunny.\"\n",
    "\n",
    "tools = [calculator, fake_weather]\n",
    "\n",
    "# --- Bind tools to the model ---\n",
    "router = llm.bind_tools(tools)\n",
    "\n",
    "# --- Simple tool loop: model decides -> we execute -> feed result back ---\n",
    "def ask(prompt: str):\n",
    "    # 1) Ask the model\n",
    "    res = router.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    # 2) If it requested tool(s), run them and return final answer\n",
    "    msgs = [HumanMessage(content=prompt), res]\n",
    "    if hasattr(res, \"tool_calls\") and res.tool_calls:\n",
    "        for tc in res.tool_calls:\n",
    "            name = tc[\"name\"]\n",
    "            args = tc[\"args\"] or {}\n",
    "            fn = next(t for t in tools if t.name == name)\n",
    "            output = fn.invoke(args)  # run the tool\n",
    "            msgs.append(ToolMessage(tool_call_id=tc[\"id\"], content=str(output)))\n",
    "\n",
    "        # 3) Give tool outputs back to the model for the final answer\n",
    "        final = llm.invoke(msgs)\n",
    "        return final.content\n",
    "\n",
    "    # No tool callâ€”model answered directly\n",
    "    return res.content\n",
    "\n",
    "print(ask(\"What's 24*19? Then tell me the (fake) weather in Dallas.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1ead3-8566-4279-96bf-fe82c1d8aec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
